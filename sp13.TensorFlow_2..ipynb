{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('third': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e51e12737c350df87399844eaf42ac3dbe26f72c45ef64352958cfe3f05cbde3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TensorFlow入門2 ロジスティック回帰実装"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "入力1\t入力2\t出力\n",
    "\n",
    "0\t0\t0\n",
    "\n",
    "1\t0\t0\n",
    "\n",
    "0\t1\t0\n",
    "\n",
    "1\t1\t1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_train = np.array([[0],[0],[0],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一引数 → tf.float32で行列要素の数値のデータ型を指定\n",
    "# 第二引数 → [None,2]で行列の形を指定\n",
    "#             (Noneの部分はデータ数)(2はデータの次元)\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "t = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valiableで重みとバイアスを用意（更新用）\n",
    "W = tf.Variable(tf.zeros([2,1]))#初期値として0を入れている\n",
    "b = tf.Variable(tf.zeros([1]))\n"
   ]
  },
  {
   "source": [
    "$$h_θ(x) = g(θ^T x).\\\\ g(z) = \\frac{1}{1+e^{−z}}.\\\\ J(\\theta)=  \\frac{1}{m}  \\sum_{i=1}^{m}[−y^{(i)} log(h_θ(x^{(i)})) − (1−y^{(i)}) log(1−h_θ(x^{(i)}))]$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor(\"Equal_2:0\", shape=(?, 1), dtype=bool)\nTensor(\"Mean_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# ロジスティック回帰をTensorFlowで実装\n",
    "# \n",
    "\n",
    "# tf.matmul()はNumpyのnp.dot()や@と同じ\n",
    "y = tf.sigmoid(tf.matmul(x, W) + b)#xとwの内積+bをシグモイドまで通す\n",
    "# 上記図の3段目の式\n",
    "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y))\n",
    "# 回帰問題で二乗和誤差関数を使用場合  tf.reduce_sum(tf.square(y - t))\n",
    "\n",
    "#勾配降下法を用いてパラメータを最適化\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "# 学習後の結果の正解が正しいかどうかの判定と正解率の計算もデータフローグラフとして定義可\n",
    "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# --------------------------------------------------------------------------\n",
    "# 1行目で結果が正解かどうか判定しています。一つ一つ見ていきましょう。まずtf.equal()は引数に指定された2つの値が等しいかどうかを判定してくれます。戻り値はBool値です。tf.sign()は引数の値が正なら1、0なら0、負なら-1を返します。yが0.5以上かどうかで結果が決まるので、y-0.5とt-0.5の符号を比較しています。\n",
    "# --------------------------------------------------------------------------\n",
    "# print(correct_prediction) \n",
    "  # #Tensor(\"Equal_2:0\", shape=(?, 1), dtype=bool)\n",
    "# print(accuracy) \n",
    "  # #Tensor(\"Mean_2:0\", shape=(), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0, Accuracy: 0.750000\n",
      "epoch: 100, Accuracy: 1.000000\n",
      "epoch: 200, Accuracy: 1.000000\n",
      "epoch: 300, Accuracy: 1.000000\n",
      "epoch: 400, Accuracy: 1.000000\n",
      "epoch: 500, Accuracy: 1.000000\n",
      "epoch: 600, Accuracy: 1.000000\n",
      "epoch: 700, Accuracy: 1.000000\n",
      "epoch: 800, Accuracy: 1.000000\n",
      "epoch: 900, Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# 計算を実装していく\n",
    "\n",
    "sess = tf.Session()#インスタンス化\n",
    "sess.run(tf.global_variables_initializer())#初期化\n",
    "\n",
    "# 学習(1000回)\n",
    "for epoch in range(1000):\n",
    "    sess.run(train_step, feed_dict={#sess.run(train_step) 勾配降下法\n",
    "        x:x_train,\n",
    "        t:y_train\n",
    "    })\n",
    "# 100回ごとに正解率を表示\n",
    "    if epoch % 100 == 0:\n",
    "        acc_val = sess.run(#accuracy numpyで返ってくる\n",
    "            accuracy, feed_dict={\n",
    "                x:x_train,\n",
    "                t:y_train})\n",
    "        print ('epoch: %d, Accuracy: %f'\n",
    "               %(epoch, acc_val))\n",
    "               #epoch=回数\n",
    "               #acc_val=正解率(回数ごと）)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ True]\n [ True]\n [ True]\n [ True]]\n[[1.9651421e-04]\n [4.9049832e-02]\n [4.9049832e-02]\n [9.3120378e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 結果の確認\n",
    "#学習結果が正しいか確認\n",
    "classified = sess.run(correct_prediction, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "#出力yの確認\n",
    "prob = sess.run(y, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "print(classified)\n",
    "# [[ True]\n",
    "# [ True]\n",
    "# [ True]\n",
    "# [ True]]\n",
    "\n",
    "print(prob)\n",
    "# [[  1.96514215e-04] 1の可能性が50％以下\n",
    "# [  4.90498319e-02]          〃\n",
    "# [  4.90498319e-02]          〃\n",
    "# [  9.31203783e-01]] 1の可能性が93%\n",
    "\n",
    "#シグモイド関数を通しているので確率で表示されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W: [[5.5699544]\n [5.5699544]]\nb: [-8.534579]\n"
     ]
    }
   ],
   "source": [
    "# 重みとバイアスの学習結果\n",
    "print('W:', sess.run(W))\n",
    "print('b:', sess.run(b))\n",
    "# W: [[ 5.5699544]\n",
    "# [ 5.5699544]]\n",
    "# b: [-8.53457928]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.       ]\n [ 5.5699544]\n [ 5.5699544]\n [11.139909 ]]\n"
     ]
    }
   ],
   "source": [
    "# 途中の値が見たい場合（デバックのため）\n",
    "mat = tf.matmul(x, W)\n",
    "y = tf.sigmoid(mat + b)\n",
    "print(sess.run(mat, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セッションを終了させる\n",
    "\n",
    "sess.close()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run() # ここに計算の実行コードを入れていく"
   ]
  },
  {
   "source": [
    "### NumPyによるスクラッチ実装との比較\n",
    "\n",
    "TensorFlowを利用した場合、NumPyでのスクラッチのように更新の式ということを考える必要はなくなりました。\n",
    "\n",
    "データフローグラフの構築は、スクラッチにおけるフォワードプロパゲーションの実装に近いと言えます。\n",
    "\n",
    "また、シグモイド関数などよく使われるものは関数化されているため、それらを組み合わせていくだけで実装することが可能です。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}